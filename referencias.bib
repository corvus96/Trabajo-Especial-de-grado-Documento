@article{Wheatstone1837,
   abstract = {An accessory pulsatile organ of an open circulatory system in insects supplying the antennae with haemolymph was investigated. The rhythm of this so-called antenna–heart is generated by a myogenic automatism and can be neuronally influenced via the nervus cardioantennalis. The action potentials of the muscle fibres show typical pre-depolarization and mostly no overshoot. A specific membrane resistance (Rm ) of about 660?cm−2 was calculated for the fibres. Some electrical coupling between the muscle fibres is presumed for synchronization of any myogenically triggered heart beat which could actually be proved experimentally by cur- rent injection in the antenna–heart. However, intercalated disks or gap junctions could not be found. Nevertheless, a good coupling factor (U2 /U1 ) between all fibres was demonstrated by parallel recordings and can be well described by a conductance model according to fibre topology.},
   author = {C. Wheatstone},
   issue = {0},
   journal = {Proceedings of the Royal Society of London},
   title = {Contributions to the Physiology of Vision.},
   volume = {4},
   year = {1837},
}

@misc{AssistiveTech,
author = {Dembys, Jacket and Gao, Yixiang and Shafiekhani, Ali and Desouza, G.N.},
year = {2019},
month = {10},
title = {Object Detection and Pose Estimation Using CNN in Embedded Hardware for Assistive Technology}
}

@misc{MartinMM,
   Author = {Martínez Montalvo Martín},
   Title = {{Técnicas de visión estereoscópica para determinar la estructura tridimensional de la escena Proyecto}},
   Publisher = {Facultad de Informática, Universidad Computense de Madrid},
   Address = {Madrid},
 Year = {2010} }

@misc{Paquetes, 
    title={El sistema de importación}, url={https://docs.python.org/es/3/reference/import.html?highlight=paquete}, 
    journal={El sistema de importación - documentación de Python - 3.9.0},
    note={Accesado el 9, de noviembre de 2020}} 
 
 @misc{PEP420, 
    title={Implicit Namespace Packages},
    Year = {2012},
    month = {4},
    url={https://www.python.org/dev/peps/pep-0420/}, 
    note={Accesado el 9, de noviembre de 2020}} 
    
 @misc{ModuloPython, 
    title={Modulos},
    url={https://www.python.org/dev/peps/pep-0420/}, 
    note={Accesado el 11, de noviembre de 2020}} 
 
 @misc{wheel, 
    title={Distribuir módulos de Python},
    url={https://docs.python.org/es/3/distributing/index.html#distributing-index}, 
    note={Accesado el 14, de noviembre de 2020}} 
 
 @article{Barnard1982,
   author = {Stephen T. Barnard and Martin A. Fischler},
   doi = {10.1145/356893.356896},
   issn = {15577341},
   issue = {4},
   journal = {ACM Computing Surveys (CSUR)},
   title = {Computational Stereo},
   volume = {14},
   year = {1982},}
@book{RSSFernando_homogeneusC,
   author = {Fernando Torres and Jorge Pomares and Pablo Gil and Santiago T. Puente and Rafael Aracil},
   title = {Robots y Sistemas Sensoriales},
   address = {Madrid},
   year = {2002},
   publisher = {Pearson Education},
   pages={69--94},
}
@book{RSSFernando_pIntrinsicosExtrinsecos,
   author = {Fernando Torres and Jorge Pomares and Pablo Gil and Santiago T. Puente and Rafael Aracil},
   title = {Robots y Sistemas Sensoriales},
   address = {Madrid},
   year = {2002},
   publisher = {Pearson Education},
   pages={196--207},
}

@book{Szeliski2020,
   abstract = {As humans, we perceive the three-dimensional structure of the world around us with apparent ease. However, despite all of the recent advances in computer vision research, the dream of having a computer interpret an image at the same level as a two-year old remains elusive. Why is computer vision such a challenging problem, and what is the current state of the art?Computer Vision: Algorithms and Applications explores the variety of techniques commonly used to analyze and interpret images. It also describes challenging real-world applications where vision is being successfully used, both for specialized applications such as medical imaging and fun consumer-level tasks such as image editing and stitching, which students can apply to their own personal photos and videos.More than just a source of "recipes", this text/reference also takes a scientific approach to basic vision problems, formulating physical models of the imaging process before inverting this process to produce the best possible descriptions of a scene. Exercises are presented throughout the book, with a heavy emphasis on testing algorithms.Suitable for either an undergraduate or a graduate-level course in computer vision, this textbook focuses on basic techniques that work under real-world conditions and encourages students to push their creative boundaries.Dr. Richard Szeliski has over twenty years' experience in computer vision research, most notably at Digital Equipment Corporation and Microsoft.},
   author = {Richard Szeliski},
   journal = {Computer Vision : Algorithms and Applications},
   title = {Computer Vision : Algorithms and Applications 2nd edition},
   year = {2020},
}

@misc{dai2020atvsnet,
      title={A-TVSNet: Aggregated Two-View Stereo Network for Multi-View Stereo Depth Estimation}, 
      author={Sizhang Dai and Weibing Huang},
      year={2020},
      eprint={2003.00711},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{CS231n,
      title={CS231n Convolutional Neural Networks for Visual Recognition}, 
      url={https://cs231n.github.io/convolutional-networks/},
      note={Accesado el 12, de febrero de 2021}}
}
@INPROCEEDINGS{Königshof, author={Königshof, Hendrik and Salscheider, Niels Ole and Stiller, Christoph},  booktitle={2019 IEEE Intelligent Transportation Systems Conference (ITSC)}, title={Realtime 3D Object Detection for Automated Driving Using Stereo Vision and Semantic Information}, year={2019}, pages={1405-1410},  doi={10.1109/ITSC.2019.8917330}}

@article{Zhang2000,
   abstract = {We propose a flexible new technique to easily calibrate a camera. It only requires the camera to observe a planar pattern shown at a few (at least two) different orientations. Either the camera or the planar pattern can be freely moved. The motion need not be known. Radial lens distortion is modeled. The proposed procedure consists of a closed-form solution, followed by a nonlinear refinement based on the maximum likelihood criterion. Both computer simulation and real data have been used to test the proposed technique and very good results have been obtained. Compared with classical techniques which use expensive equipment such as two or three orthogonal planes, the proposed technique is easy to use and flexible. It advances 3D computer vision one more step from laboratory environments to real world use. The corresponding software is available from the author's Web page. © 2000 IEEE.},
   author = {Zhengyou Zhang},
   doi = {10.1109/34.888718},
   issn = {01628828},
   issue = {11},
   journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
   title = {A flexible new technique for camera calibration},
   volume = {22},
   year = {2000},
}

@article{Hartley1999,
   abstract = {This paper gives a new method for image rectification, the process of resampling pairs of stereo images taken from widely differing viewpoints in order to produce a pair of `matched epipolar projections'. These are projections in which the epipolar lines run parallel with the x-axis and consequently, disparities between the images are in the x-direction only. The method is based on an examination of the fundamental matrix of Longuet-Higgins which describes the epipolar geometry of the image pair. The approach taken is consistent with that advocated by Faugeras (1992) of avoiding camera calibration. The paper uses methods of projective geometry to determine a pair of 2D projective transformations to be applied to the two images in order to match the epipolar lines. The advantages include the simplicity of the 2D projective transformation which allows very fast resampling as well as subsequent simplification in the identification of matched points and scene reconstruction.},
   author = {Richard I. Hartley},
   doi = {10.1023/A:1008115206617},
   issn = {09205691},
   issue = {2},
   journal = {International Journal of Computer Vision},
   title = {Theory and practice of projective rectification},
   volume = {35},
   year = {1999},
}

@article{Scharstein2002,
   abstract = {Stereo matching is one of the most active research areas in computer vision. While a large number of algorithms for stereo correspondence have been developed, relatively little work has been done on characterizing their performance. In this paper, we present a taxonomy of dense, two-frame stereo methods. Our taxonomy is designed to assess the different components and design decisions made in individual stereo algorithms. Using this taxonomy, we compare existing stereo methods and present experiments evaluating the performance of many different variants. In order to establish a common software platform and a collection of data sets for easy evaluation, we have designed a stand-alone, flexible C++ implementation that enables the evaluation of individual components and that can easily be extended to include new algorithms. We have also produced several new multi-frame stereo data sets with ground truth and are making both the code and data sets available on the Web. Finally, we include a comparative evaluation of a large set of today's best-performing stereo algorithms. © 2002 Kluwer Academic Publishers.},
   author = {Daniel Scharstein and Richard Szeliski},
   doi = {10.1023/A:1014573219977},
   issn = {09205691},
   issue = {1-3},
   journal = {International Journal of Computer Vision},
   title = {A taxonomy and evaluation of dense two-frame stereo correspondence algorithms},
   volume = {47},
   year = {2002},
}


@book{Atienza2018,
   abstract = {Apply deep learning techniques, autoencoders, GANs, variational autoencoders, deep reinforcement learning, policy gradients, and more},
   author = {Rowel Atienza},
   journal = {Packt Publishing},
   title = {Advanced Deep Learning with Keras: Apply deep learning techniques, autoencoders, GANs, variational autoencoders, deep reinforcement learning, policy gradients, and more},
   year = {2018},
}

@book{Krishnendu,
   author = {Krishnendu Kar},
   journal = {Packt Publishing},
   title = {Mastering Computer Vision with TensorFlow 2.x},
   year = {2020},
}

@misc{residualBlocksPaper,
  doi = {10.48550/ARXIV.1603.05027},
  
  url = {https://arxiv.org/abs/1603.05027},
  
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Identity Mappings in Deep Residual Networks},
  
  publisher = {arXiv},
  
  year = {2016},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{fullyConectedNet,
  doi = {10.48550/ARXIV.1411.4038},
  
  url = {https://arxiv.org/abs/1411.4038},
  
  author = {Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Fully Convolutional Networks for Semantic Segmentation},
  
  publisher = {arXiv},
  
  year = {2014},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{stereopi_quickstart_guide,
  
  url = {https://wiki.stereopi.com/index.php?title=StereoPi_v2_Quick_Start_Guide},
  
  author = {Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
  
  
  title = {StereoPi V2 quick start guide},
  
  publisher = {wikipedia},
  
  year = {2014},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@book{LearningOpenCV3,
    author = { Adrian Kaehler, Gary Bradski},
    title = {Learning OpenCV 3: computer vision in C++ with the
OpenCV library},
    address = {California, USA},
    year = {2016},
    publisher = {O'Reilly Media, Inc.},
}

@article{yolov3,
  title={YOLOv3: An Incremental Improvement},
  author={Redmon, Joseph and Farhadi, Ali},
  journal = {arXiv},
  year={2018}
}

@misc{FPN,
  doi = {10.48550/ARXIV.1612.03144},
  
  url = {https://arxiv.org/abs/1612.03144},
  
  author = {Lin, Tsung-Yi and Dollár, Piotr and Girshick, Ross and He, Kaiming and Hariharan, Bharath and Belongie, Serge},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Feature Pyramid Networks for Object Detection},
  
  publisher = {arXiv},
  
  year = {2016},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{pascal-voc-2012,
	author = "Everingham, M. and Van~Gool, L. and Williams, C. K. I. and Winn, J. and Zisserman, A.",
	title = "The {PASCAL} {V}isual {O}bject {C}lasses {C}hallenge 2012 {(VOC2012)} {R}esults",
	howpublished = "http://www.pascal-network.org/challenges/VOC/voc2012/workshop/index.html"}	

