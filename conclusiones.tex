El desarrollo de este trabajo nos lleva a concluir lo siguiente, como producto de la investigación se lograron declarar dos técnicas de reconocimiento; una basada en segmentación con la arquitectura de RNA Deeplab y otra fundamentada en detección de objetos con la arquitectura conocida como YOLO. Se analizaron los requerimientos necesarios del software a desarrollar de acuerdo con las capacidades del hardware disponible, además de tener como fin simplificar el uso del mismo para cualquier usuario, dicho análisis permitió definir la arquitectura del paquete utilizando patrones de diseño, los cuales buscaban maximizar la reutilización de código y posibilitar la independencia entre módulos.
\\
\\
Se compararon los modelos de aprendizaje automático Deeplab y YOLO, lo que trajo como resultado en la elección de la red YOLO, la cual fue entrenada mediante Google Colab, empleando el conjunto de datos PASCAL VOC y posteriormente evaluada a través de la métrica mAP, a su vez se implementó dicha red utilizando sus pesos originales (entrenados con el conjunto de datos de COCO) para comprobar su comportamiento en el reconocimiento de objetos en vídeo. Se implementó un algoritmo de posicionamiento que utiliza la red YOLO para la detección de objetos, el algoritmo SGBM para la correspondencia y posterior cálculo de disparidad y para determinar los píxeles que corresponden con el objeto en cuestión dentro de las ventanas de detección se aprovecho del algoritmo de umbralización de Otsu.
\\
\\
Para comprobar el funcionamiento adecuado del paquete se diseñaron un conjunto de pruebas unitarias almacenadas en la carpeta tests del directorio del paquete, que tienen como fin probar diversos argumentos en los métodos y clases de los módulos, para tomar en cuenta aquellos casos que pueden generar algún error, a su vez se generaron pruebas experimentales que se pueden hallar en el capítulo VI, las cuales verifican que los resultados se encuentren de acuerdo a lo previsto, una vez validado, se elaboró el documento descriptivo del paquete el cual se halla en el siguiente enlace https://corvus96.github.io/PyTwoVision/html/index.html. Finalmente se empaquetó y distribuyo el paquete en el PyPI utilizando como herramienta de distribución setuptools.