En este capitulo se declarara el problema que fundamenta este trabajo, basado en el desarrollo de un paquete de python que permita obtener la localización de objetos en una escena con el fin de facilitar el desarrollo de sistemas de control basados en visión por computador. Además se expone la justificación, objetivos, alcance, factibilidad y antecedentes para este proyecto.

\section{Planteamiento del problema}
Las técnicas de control y automatización de procesos, aplicadas en el campo de la robótica, permiten realizar tareas sencillas en entornos estructurados donde se conoce el espacio de trabajo por completo y los objetos que interactúan en el mismo. No obstante, hoy en día los autómatas son capaces de realizar tareas complejas en espacios de trabajo dinámicos, es decir, entornos que varían en el tiempo, donde los eventos son de carácter estocástico. Sin embargo, para lograr dicha proeza es necesario expandir el conjunto de técnicas de control convencionales mediante la incorporación de nuevos algoritmos y estrategias.  

Para resolver problemas de robótica en entornos complejos, las mejores estrategias actuales son aquellas que dotan al robot de la capacidad de aprender y adaptarse a los cambios, estas técnicas de inteligencia artificial requieren de información del entorno la cual es extraída mediante algoritmos de VC que otorgan al autómata la habilidad de reconocer los objetos en su campo de visión y a partir de imágenes en 2D captar las posiciones relativas entre los objetos de interés y el robot. 

Existen diversas formas de conocer las posiciones de de objetos en escenas, una de ellas es la visión estéreo, aunque su implementación puede ser complicada si no se poseen los conocimientos apropiados, por este motivo se busca desarrollar un paquete que facilite la implementación de técnicas de posicionamiento de objetos en escenas mediante visión estéreo y reconocimiento basado en AA.
\section{Justificación}
El paquete para el posicionamiento basado en reconocimiento, facilitara la implementación de estrategias de control que empleen visión por computador a ingenieros y programadores. Y servirá para la comprensión de algunas de las técnicas de VC implementadas mediante tecnologías Open Source, como lo son Tensorflow, Keras y OpenCV.

Además de establecer algunos métodos para fortalecer los conocimientos en el área de control  que se imparten en la Escuela de Ingeniería Eléctrica, el estudio de tecnologías que se encuentran en auge usadas en el campo de inteligencia artificial aplicada a la robótica. 
\section{Objetivos}
\subsection{Objetivo general}
Desarrollar un paquete en Python para el posicionamiento de objetos en una escena empleando visión estereoscópica y técnicas de reconocimiento basadas en aprendizaje automático.
\subsection{Objetivo especifico}
\begin{itemize}
    \item Describir al menos dos técnicas de reconocimiento basadas en aprendizaje automático empleadas en el posicionamiento de objetos.
    \item Realizar el análisis de requerimientos necesarios del software a desarrollar.
    \item Definir la arquitectura del software.
    \item Definir los patrones de diseño aplicables.
    \item Seleccionar el modelo de aprendizaje automático para el reconocimiento de imágenes en vídeo.
    \item Implementar el sistema de reconocimiento con Tensorflow/Keras y OpenCV, en el lenguaje de programación Python.
    \item Implementar un algoritmo para el posicionamiento, basado en el reconocimiento de objetos en la escena.
    \item Diseñar un banco de pruebas para la validación del paquete.
    \item Elaborar un documento descriptivo del paquete con ejemplos de uso.
    \item Empaquetar el software para su distribución o instalación.
\end{itemize}
\section{Alcance y limitaciones}
El presente trabajo estará acotado en el desarrollo del paquete para el posicionamiento de objetos, en un entorno cerrado con la iluminación adecuada, para el correcto funcionamiento del modulo de reconocimiento. Se realizaran pruebas mediante cámaras de teléfono cuyos datos serán enviados a través de la aplicación gratuita de android IP webcam, para luego ser procesados en un computador o en un dispositivo embebido.
\section{Análisis de factibilidad}
Para la realización de este trabajo se cuenta con la documentación necesaria, además de casos de estudio donde lograron implementar sistemas similares en computadores y microcontroladores de gama baja y media. En caso de requerir la potencia de procesamiento que ofrece un servidor en la nube, se tiene un internet estable. El autor ya posee cierto nivel de conocimiento en las áreas de visión por computador y aprendizaje automático. Por otro lado se cuenta con el apoyo del ingeniero Carlos Gonzalez el cual se comprometió en prestar ayuda en el área de aprendizaje automático mediante el framework Tensorflow/Keras.

De ser necesaria alguna otra herramienta o equipo el autor cubrirá los gastos. Y la cantidad de tiempo que se propone se considera suficiente para la realización de este trabajo.
\section{Antecedentes}
En primer lugar se tiene el trabajo de fin de máster presentado en 2010 por
Martín Montalvo Martínez en la Universidad computense de Madrid, titulado "Técnicas de visión estereoscópica para determinar la estructura tridimensional de la escena"  \cite{MartinMM}.

En este trabajo se estudió la efectividad de diversos métodos de correspondencia estereoscópica, las técnicas utilizadas fueron comparadas mediante un estimador conocido como Error Cuadrático Medio (ECM), con este estimador se comparó el mapa de disparidad obtenido con cada uno de los métodos y el mapa de disparidad considerado como correcto "ground-truth". 
\\
El estudio se centro en la factibilidad para la implementación de sistemas estereoscópicos que han de operar en el exterior y bajo condiciones adversas, ya que las actividades de investigación planteadas por el grupo ISCAR en 2010 estaban orientadas en la navegación autónoma de vehículos. En estos vehículos el principal problema era el de la correspondencia estereoscópica, por este motivo el proyecto se oriento en la identificación de un algoritmo apropiado para el caso correspondiente.
\\
\\
La metodología empleada por el autor consistió en primer lugar, en realizar una revisión bibliográfica sobre los métodos descritos hasta la fecha, luego selecciono aquellos que encajaran con la problemática de estudio, para posteriormente implementarlos en el entorno de Matlab en su versión 2007b utilizando imágenes sintéticas y reales de las que poseía información sobre los mapas de disparidad. Luego evaluó su efectividad mediante el ECM y se obtuvo que de los métodos estudiados el que presenta mejores resultados es aquel basado en la segmentación y medida de similitud, además dicho método  se posiciona como el segundo más rápido al evaluar el promedio de tiempo. Sin embargo el problema que plantea radica en que los objetos existentes en la escena con una tonalidad uniforme y con distintos valores de disparidad son representados incorrectamente en el mapa final. Con este trabajo de maestría se logro comparar el comportamiento de varias metodologías que permiten obtener una representación tridimensional de una escena mediante visión estéreo.
\\
\\
En octubre Dembys, Gao, Shafiekhani, y Desouza (2019) presentaron un paper en una conferencia titulado "Detección de objetos y estimación de pose utilizando CNN (Convolutional Neural Networks) en hardware integrado para tecnología de asistencia" \cite{AssistiveTech}.
\\
\\
En este trabajo se desarrollo un algoritmo de visión estéreo el cual puede ser ejecutado en una placa Raspberry Pi 3 utilizando dos camaras RPi V2 como sensores. Este sistema se interconecta a un computador mediante el framework ROS (Robot Operating System) el cual posee una interfaz donde muestra el resultado final del sistema estereoscópico. El algoritmo utilizado esta compuesto por dos fases principales, la primera sería la fase de detección donde emplea una red neuronal convolucional (CNN) llamada MobileNet SSD (Single Shot MultiBox Descriptor) para reconocer y seguir los objetos de interés en una escena, mientras que en la fase de estimación de posición emplea correspondencias estéreo para reconstruir en 3D las coordenadas espaciales basadas en el algoritmo ORB (Oriented FAST and Rotated BRIEF) desarrollado por OpenCV. La motivación de esta investigación fue el desarrollo de equipamiento médico de bajo coste que pueda servir de apoyo para personas con discapacidades.
\\
\\
Los investigadores compararon sus resultados con la tecnología del estado del arte DOPE (Deep Object Pose Estimation) y llegaron a la conclusión de que es posible integrar redes ligeras para la detección de objetos en tiempo real y estimación de pose en tecnologías de asistencia a un bajo costo. Sin embargo, el algoritmo propuesto depende de la iluminación de la escena y la calidad de las características extraídas del objeto de destino, aunque los resultados demuestran que su enfoque también puede ser empleado en tareas de pick-and-place de brazos manipuladores.
